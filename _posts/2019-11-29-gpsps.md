---
layout: posts
title:  "Gaussian Process Speech Synthesis (Draft)"
date:   2019-12-29 00:02:15 +0000
categories: stats python
entries_layout: grid
---

Very untidy first working draft of the idea mentioned on the efficient computation page. Here, I fit a spectral mixture to some audio data. I'll implement efficient sampling later, and I'll replace the arbitrary way this is trained with an LSTM-RNN to go straight from text/mel-spectrograms to waveforms.
The idea though, is that we fit a gaussian process to some waveforms in the frequency domain rather than the time domain. This also showcases the power of SymPy. This is, to some extent, original work - I drew from Richard Turner's thesis for the amplitude demodulation part and Andrew Gordon Wilson's papers for the spectral kernel. This was a learning excercise - it's not meant to be groundbreaking.

Synthesized audio sample:

 Separated Sample:
 <audio controls>
   <source src="/audio/life_synth.wav" type="audio/wav">
   Browser cannot play audio.
 </audio> <br>

<details open>
<summary> Python Code </summary>
 
{%highlight python%}

import pystan
import sympy as sy
import numpy as np
import pickle as pkl
import tensorflow as tf
from tqdm import tqdm, trange
import matplotlib.pyplot as plt
from scipy.linalg import toeplitz
from scipy.io import wavfile as wav
from scipy.signal import stft, find_peaks
from scipy.interpolate import UnivariateSpline

sy.init_printing()
md = sy.functions.Abs
sess = tf.InteractiveSession()
plt.style.use("ggplot"); plt.ion()

def spectrum(x, u = 1, return_freq = True):
	n = len(x)
	intm = np.fft.fft(x)
	intm = (intm * intm.conjugate()).real/n
	intm = intm * u/n 
	psd = intm[1:int(np.ceil(0.5 * (n + 1)))]
	if return_freq:
		freq = range(1, len(psd) + 1) 
		freq = np.array(freq, dtype = float)
		freq *= 0.5*n / (u * len(psd))
		return freq, psd
	else:
		return psd

class SimulationData:
	def __init__(self):
		self.num_data = None
		self.time = None
		self.upper_lim = None
		self.kernel_func = None
		self.cholesky_fac = None
	def gen_grid(self, num_data = 500, upper_lim = 5):
		self.num_data = num_data
		self.upper_lim = upper_lim
		self.time = np.linspace(0, upper_lim, num_data)
	def gen_chol(self, kernel_func = None):
		if kernel_func is None:
			kernel_func = self.kernel_func
		C = toeplitz(kernel_func(self.time))
		C += np.identity(len(self.time))*1e-7
		C = np.linalg.cholesky(C)
		self.cholesky_fac = C
	def simulate(self):
		C = self.cholesky_fac
		z = np.random.normal(size = self.num_data)
		return C @ z
	def gen_expcos_kern(self):
		sm = dict(r = sy.symbols("r", real = True),
			w = sy.symbols("w", real = True, positive = True),
			l = sy.symbols("l", real = True, positive = True),
			p = sy.symbols("p", real = True, positive = True),
			s = sy.symbols("s", real = True, positive = True))
		self.symbols = sm
		pass

def spectrum_check(l = 0.5, s = 2.0, p = 0.5, n = 10000):
	r, w = sy.symbols("r, w", real = True)
	K = s**2 * sy.exp(-(r/l)**2) * sy.cos(2*p*sy.pi*r)
	S = sy.fourier_transform(K, r, w)
	S = sy.lambdify(w, S)
	K = sy.lambdify(r, K)

	data = SimulationData()
	data.gen_grid()
	data.gen_chol(K)

	freq, psd = spectrum(data.simulate(), data.upper_lim)
	for i in range(n - 1):
		psd += spectrum(data.simulate(), data.upper_lim)[1]

	s_t = S(data.time)
	plt.plot(data.time, s_t, label = "Theoretical")
	plt.xlim(-0.5, data.upper_lim)
	plt.plot(freq, psd/n, label = "Empirical")
	plt.xlabel("Frequency")
	plt.ylabel("Power")
	plt.legend()

def convergence_check():
	l, s, p, u = 0.5, 2.0, 0.5, 5.0
	r, w = sy.symbols("r, w", real = True)
	s_p, p_p, l_p = sy.symbols("s, p, l", real = True, positive = True)

	K = s**2 * sy.exp(-(r/l)**2) * sy.cos(2*p*sy.pi*r)
	K_t = s_p**2 * sy.exp(-(r/l_p)**2) * sy.cos(2*p_p*sy.pi*r)
	S = sy.fourier_transform(K_t, r, w)
	S = sy.lambdify([w, l_p, p_p, s_p], S) # , "tensorflow")
	K = sy.lambdify(r, K)
	W = s_p**2 / sy.sqrt(2) # sy.fourier_transform((s_p**2)*sy.exp(-(r/1e-20)**2)/sy.sqrt(2*sy.pi*(1e-20)**2), r, w)
	W = sy.lambdify(s_p, W)

	data = SimulationData()
	data.gen_grid(upper_lim = u)
	data.gen_chol(K)

	l_p_0 = tf.Variable(1.1)
	p_p_0 = tf.Variable(2.2)
	s_p_0 = tf.Variable(0.9)

	l_param = tf.clip_by_value(l_p_0, 1e-5, 1e5)
	p_param = tf.clip_by_value(p_p_0, 1e-5, 1e5)
	s_param = tf.clip_by_value(s_p_0, 1e-5, 1e5)

	freq_obs, spec_obs = spectrum(data.simulate(), u)
	freq_obs = np.array(freq_obs, dtype = "float32")
	spec_obs = np.array(spec_obs, dtype = "float32")

	spec_const = tf.constant(spec_obs)

	add_term = S(freq_obs, l_param, p_param, s_param) + 1e-10
	loss = tf.reduce_sum((spec_const - add_term)**2) # likelihood is too unstable
	step = tf.train.AdamOptimizer().minimize(loss = loss, var_list = [l_p_0, p_p_0, s_p_0])

	sess.run(tf.initialize_all_variables())

	for i in tqdm(range(2000)):
		if i % 50 == 0:
			freq_obs, spec_obs = spectrum(data.simulate(), u)
			freq_obs = np.array(freq_obs, dtype = "float32")
			spec_obs = np.array(spec_obs, dtype = "float32")
			print(sess.run(loss))
		sess.run(step, feed_dict = {spec_const: spec_obs})
	print(np.round(sess.run([l_param, p_param, s_param]), 2))
	print(np.round([l, p, s], 2))

if __name__ == "__main__":

	life_sr, life = wav.read("/Users/adityaravuri/Downloads/life.wav")
	# life_sr, life = wav.read("/Users/adityaravuri/Desktop/sample_gn/slightly.wav")
	life = np.array(life[:, 0], dtype = "float64")
	life_scale = life.std()
	life /= life_scale
	n_t = len(life)
	t = n_t/life_sr

	lsc = t/20
	n_u = 20
	t_u = np.linspace(0, t, n_u)
	t_f = np.linspace(0, t, n_t)

	K12 = np.tile(t_u, n_t).reshape(n_t, n_u) -\
		np.repeat(t_f, n_u).reshape(n_t, n_u)
	K22 = np.tile(t_u, n_u).reshape(n_u, n_u) -\
		np.repeat(t_u, n_u).reshape(n_u, n_u)

	K12 = np.exp(-(K12/lsc)**2)
	K22 = np.exp(-(K22/lsc)**2) + np.identity(n_u)*1e-10
	K1222i = K12 @ np.linalg.inv(K22)
	K22c = np.linalg.cholesky(K22)

	model_code = """
	data {
		int n;
		int n_s;
		real seg_a[n];
		matrix[n, n_s] factor;
		cholesky_factor_cov[n_s] K22c;
	}
	parameters {
		real<lower = -7.5, upper = 10> mu;
		vector<lower = -7.5, upper = 10>[n_s] sigma;
	}
	transformed parameters {
		vector[n] sigma_vec;
		sigma_vec = rep_vector(mu, n) +
			factor*(sigma - rep_vector(mu, n_s));
	}
	model {
		sigma ~ multi_normal_cholesky(rep_vector(mu, n_s), K22c);
		seg_a ~ normal(0, 1e-10 + log(1 + exp(sigma_vec)));
	}
	"""

	data_list = dict(n = n_t, n_s = n_u, seg_a = life,
		factor = K1222i, K22c = K22c)

	# model = pystan.StanModel(model_code = model_code)
	# with open('amp_model.pkl', 'wb') as f:
	# 	pkl.dump(model, f, protocol = pkl.HIGHEST_PROTOCOL)

	with open('amp_model.pkl', 'rb') as f:
		model = pkl.load(f)

	fit = model.optimizing(data = data_list, as_vector = False)
	while fit['value'] < -2011.08:
		temp = model.optimizing(data = data_list, as_vector = False)
		if temp['value'] > fit['value']:
			fit = temp

	plt.plot(np.log(1 + np.exp(fit['par']['sigma_vec'])) *  2)
	plt.plot(np.log(1 + np.exp(fit['par']['sigma_vec'])) * -2)
	plt.plot(life)

	b_a = int(n_t/4); b_b = int(n_t/2); b_c = int(n_t*0.825)
	plt.vlines(b_a, -3, 3)
	plt.vlines(b_b, -3, 3)
	plt.vlines(b_c, -3, 3)

	stn = life/np.log(1 + np.exp(fit['par']['sigma_vec']))

	segments = (stn[:b_a], stn[b_a:b_b], stn[b_b:b_c], stn[b_c:])

	# f, s = spectrum(segments[0], u_a); plt.plot(f, np.log(s)); plt.plot(f, np.log(S(f, 0.1, 0.2, 1) + W(1e-5)))
	# plt.plot(np.log(np.sum((stft(segments[1])[2] * stft(segments[1])[2].conj()).real, axis=1)))

	r, w = sy.symbols("r, w", real = True)
	s, p, l = sy.symbols("s, p, l", real = True, positive = True)

	K = s**2 * sy.exp(-(r/l)**2) * sy.cos(2*p*sy.pi*r)
	S = sy.fourier_transform(K, r, w)
	S = sy.lambdify([w, l, p, s], S, "tensorflow")
	K = sy.lambdify([r, l, p, s], K)
	W = s**2 / sy.sqrt(2.0)
	W = sy.lambdify(s, W, "tensorflow")

	v = lambda x: tf.exp(tf.Variable(x))
	generators = []

	for seg in segments:

		freq_obs, spec_obs = spectrum(seg, t * len(seg)/n_t)
		freq_obs = np.array(freq_obs, dtype = "float32")
		spec_obs = np.array(spec_obs, dtype = "float32") + 1e-10

		sigma = 1/(1 + v(3.))

		# frequency selection is arbitrary for now
		ps_to_add = 3
		ps_non_trainable = ps_to_add
		ps_to_add = freq_obs[np.isin(spec_obs, np.sort(spec_obs)[-ps_to_add:])]
		l_ps = [v(-3.) for i in range(len(ps_to_add))]
		p_ps = [i for i in ps_to_add]
		s_ps = [1/(1 + v(np.random.uniform(-0.2, 0.2))) for i in range(len(ps_to_add))]

		ps_to_add = freq_obs[find_peaks(UnivariateSpline(freq_obs, np.log(spec_obs))(freq_obs))[0]]
		ps_non_trainable += len(ps_to_add)
		l_ps += [v(np.random.uniform(-1, -3)) for i in range(len(ps_to_add))]
		p_ps += [i for i in ps_to_add]
		s_ps += [1/(1 + v(np.random.uniform(-0.2, 0.2))) for i in range(len(ps_to_add))]

		ps_to_add = 3
		ps_to_add = [v(np.random.uniform(0, 2)) for i in range(ps_to_add)]
		l_ps += [v(np.random.uniform(-1, -3)) for i in range(len(ps_to_add))]
		p_ps += [i for i in ps_to_add]
		s_ps += [1/(1 + v(np.random.uniform(-0.2, 0.2))) for i in range(len(ps_to_add))]

		def spec_gen(x):
			add_term = W(sigma) + 1e-30
			for i in range(len(p_ps)):
				add_term += S(x, l_ps[i], p_ps[i], s_ps[i])
			return add_term

		add_term = spec_gen(freq_obs)

		loss = tf.reduce_sum((tf.log(spec_obs) - tf.log(add_term))**2) # likelihood is too unstable
		step = tf.train.AdamOptimizer(0.005).minimize(loss = loss)

		sess.run(tf.initialize_all_variables())

		looper = trange(10000, desc = 'ML')
		for i in looper:
			sess.run(step)
			if i % 50 == 0: looper.set_description('Loss: %g' % sess.run(loss))

		l_ps = sess.run(l_ps); p_ps = p_ps[:ps_non_trainable] + sess.run(p_ps[ps_non_trainable:])
		s_ps = sess.run(s_ps); sigma = sess.run(sigma)

		def kern(r):
			res = np.zeros(len(r))
			res[r == 0] = sigma
			for i in range(len(p_ps)):
				res += K(r, l_ps[i], p_ps[i], s_ps[i])
			return res

		test_data = SimulationData()
		test_data.gen_grid(int(len(seg)/2), t * len(seg)/n_t)
		test_data.gen_chol(kern)
		generators.append(test_data)
		# plt.plot(test_data.simulate())

		# x = np.linspace(freq_obs.min(), freq_obs.max(), 10000, dtype = "float32")
		# plt.plot(freq_obs, np.log(spec_obs))
		# plt.plot(x, np.log(sess.run(spec_gen(x))))

	# to work on conditioning between segments and efficient sampling
	audio = np.hstack([generators[i].simulate() for i in range(len(generators))])
	audio = audio * np.log(1 + np.exp(fit['par']['sigma_vec']))[np.sort(np.random.choice(range(n_t), len(audio)))]
	audio_to_write = np.array(life_scale*audio, dtype = "int16")
	wav.write("life_synth.wav", life_sr//2, np.repeat(audio_to_write, 2).reshape(-1, 2))

{% endhighlight %}
 
</details>
