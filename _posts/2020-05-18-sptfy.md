---
layout: posts
title:  "Modelling with Spotify Data"
date:   2020-06-03 00:22:00 +0100
categories: stats python R
entries_layout: grid
---

The main objective of this post was just to write about my typical workflow and views rather than come up with a great model. The structure of this data is also outside my immediate domain so I thought it'd be fun to write up a small diary on making a model with it.

> _**Objective**_: Predict the probability of skipping a track given a song and the user journey.

Before we dive in, here are a couple of interesting reads from the Spotify blog. [This article](https://benanne.github.io/2014/08/05/spotify-cnns.html) is a good read on deep learning and collaborative filtering at Spotify. [This article](https://labs.spotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/) is an interesting one about the ML pipeline that's geared towards the problems Spotify faces. Finally, [this article](https://labs.spotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/) shows one of Spotify's data discovery systems.

## Data Management & Platform

The data that I'm using is the [Spotify](https://arxiv.org/abs/1901.09851) [Streaming Sessions Dataset](https://research.spotify.com/datasets).

Before I got into the task and modelling, I needed to figure out how to manage the data.

I'm running an Ubuntu Server (18.04) on a PC that I built two years ago. I've got 12gigs of RAM and around 30gigs of space that I can dedicate to this project on an SSD. At the moment, the file systems I'm using are ext4 and exfat (I've heard about using OpenZFS for postgres and the Hadoop HDFS but I'm not going to try these out here because I don't know much about them). If this was for production, I'd think a lot more about data redundancy, etc.

The data is around 50GB and sits as a collection of CSV files in a tar.gz. Initially, I considered using a postgres database and I copied over two CSVs (using R's `DBI::dbWriteTable`), but the table size (as seen in `/var/lib/postgresql/12/main/base/`) was larger than the CSV, so I'd go way over budget in terms of storage if I were to use postgres as is.

Instead, I opted for Spark. Spark/Sparklyr (an R API for Spark) supports lazy-reading of compressed CSVs and commands are optimized even when working on a single node. If I use tensorflow/keras for this project, I'll be able to write a generator using pandas for batch processing, so this setup should be sufficient for exploration and modeling (Spark also supports GLMs and some other stats/ML models).

Memory issues shouldn't be a problem as long as queries are written in a smart way - that said I'll still use a sample of the sessions data (around 2% of it) for exploration because it's just easier to work with. I also had to get the right version of the Java SDK working before Spark worked out. I'll use Spark and the full data later after exploration.

<details>
<summary> (Click to Expand) R Code for Data Check </summary>
 
{%highlight R%}

library(sparklyr)
library(dplyr)

config = spark_config()
config$`sparklyr.shell.driver-memory` <- '15G'
config$spark.executor.memory <- '15G'
config$spark.memory.fraction <- 0.9

data_path = '/media/training_set/zipped/'
java_path = '/usr/lib/jvm/java-8-openjdk-amd64/'
spark_path = '/home/aditya/spark/spark-2.4.3-bin-hadoop2.7/'

Sys.setenv(JAVA_HOME = java_path)

sc = spark_connect(master = 'local', spark_home = spark_path)
data = spark_read_csv(sc, path = data_path, memory = F)

skips_by_song = data %>%
	group_by(track_id_clean, not_skipped) %>%
	summarize(count = n()) %>%
	collect()

{% endhighlight %}
 
</details> <br>

I'll also detail some bash commands that I normally use. Commands that I used in this section:
 * `ssh -Y aditya@local_ip`: SSH with X11 forwarding
 * `psql`: PostgreSQL Terminal
 * `sudo (-u)`: To establish dominance (as another user)
 * `sudo mount /dev/sda7 /media`: Mount external SSD to `/media`
 * `sudo fdisk -l`: Disk information
 * `ls -lha`: List all, in a human friendly way
 * `cd -`: Go back to previous directory
 * `apropos`: Help with command, list of similar commands
 * `sudo chmod -R 777 media/`: CAUTION advised, make all files read/write-able by everyone
 * `tar -xvf` and `tar -tvf file.tar.gz > file_list`: Extract file, list files in tar archive
 * `find ~ -maxdepth 5 -name x*`: Find file containing 'x'

## Initial Exploration

The `tracks` dataframe contains an id, duration, release year, popularity estimate, auditory features (e.g. acousticness, danceability) and some kind of latent representation (acoustic_vector). All these are numeric.

The `sessions` dataframe is described in the dataset paper so I won't repeat it here, but it's basically a bunch of sessions with multiple tracks with information about whether or not they were skipped.

<details>
<summary> Read data </summary>
 
{%highlight R%}

library(ggplot2)
library(magrittr)
library(data.table)

tracks <- dir('track_features', full.names = T) %>%
	lapply(fread) %>% rbindlist

sessions <- dir('training_set', full.names = T) %>%
	lapply(fread) %>% rbindlist

setnames(sessions, 'track_id_clean', 'track_id')
sessions[, date := as.Date(date)]
sessions <- merge(sessions, tracks, all.x = T, by = 'track_id')

{% endhighlight %}

</details> <br>

Below, I've rounded track duration and plotted average acousticness scores by track duration.

<details>
<summary> Example scatterplot code </summary>
 
{%highlight R%}

plot_frame <- tracks[, .(mean_acousticness = mean(acousticness)),
					 by = .(duration = round(duration * 2)/2)]

p <- ggplot(plot_frame)
p <- p + aes(x = duration, y = mean_acousticness)
p <- p + geom_point(alpha = 0.1)
p <- p + xlim(NA, 1000)
p <- p + ylim(0.25, 0.75)
p <- p + labs(x = 'Duration', y = 'Mean Acousticness')
p

{% endhighlight %}

</details> <br>

<center> <img src="/images/spotify/durac.png" width="50%"> </center>

Most plots I normally look at are scatterplots, histograms, autocorrelation estimates and spectra. Filtering, group-bys and aggregating usually gets you a long way to understanding distributions, conditional distributions and first and second order effects (mean dependences and correlations).

---
_**Sidecomment**_

A note about scatterplots because I love them so much. Typically, the kind of effect I'm looking for on a scatterplot is a graph dependence that looks like $$ T \rightarrow X $$ (2D) or $$ X \rightarrow Z \leftarrow Y $$ (3D).

What this means is that, I'm looking for the effect of one variable (like time, age - something that's usually given, which is not as such stochastic) on another that _is_ stochastic. As an example, this can leads us to see what the function $$E(X(t))$$ may possibly look like.

A graph based on data is like an estimator - there's an underlying function that you want to discover and you see a lot of noise on top of this. In the example above - we see mean acoustic scores by duration. For longer durations, there's fewer data points, so we see heteroskedasticity. The _**underlying function though**_, it's makes sense for it to be continuous (maybe even smooth).

Be _**very**_ careful when plotting stochastic variables on each other - I personally feel very uncomfortable seeing plots of $$ (X(t), Y(t)) $$, where these are time series. This is because, we usually only see one observation of the time series - and with autocorrelation and non-stationarity, one can see spurious stuff. Try plotting two stationary (and long-lengthscale) GPs against each other; half the time you'd see positive correlations and half the time negative. Irl, we only see one observation of the processes so we can't tell if the correlation we see would be there after a million alternate samples. If the processes are not stationary, the plot becomes hopeless.

In the plot above, we're dealing with an undirected graph that looks $$duration - acousticness$$ (I'm guessing). Moreover, we've got many independent observations for both variables. Mean acousticness as a function of duration seems more prominent though.

There are times where plots of stochastic variables on each other are super helpful. Below is an example of a plot I made (using plotly, colored by time) with the LANL data (I can't remember what the rv.s were, but it was something like $$(X, \frac{\Delta X}{\Delta t}, \frac{\Delta^2 X}{\Delta t^2}$$). You can clearly see a deterministic relationship.

<center> <img src="/images/spotify/dynpl.png" width="25%"> </center>

---

Below, is a list of histograms corresponding to variables in the `tracks` dataframe.

<center> <img src="/images/spotify/hists.png" width="95%"> </center>

An interesting thing about this data is that we've got four million independent observations of a bunch of acoustic features of different songs. Given the independence, we can try to figure out the graph (CPDAG) that might be behind the variables.

I used an R implementation of the PC algorithm to work out a possible graph that might've generated this data. There is an assumption here about multivariate normality, so I log-transformed some of the fatter-tailed variables before working out the correlation matrix. I used a `networkD3` script from [here](https://www.r-bloggers.com/network-visualization-part-6-d3-and-r-networkd3/) to make a nice viz of the CPDAG although it really needs to be refined.

<details>
<summary> PC alg code for CPDAG </summary>
 
{%highlight R%}

library(pcalg)
library(igraph)
library(networkD3)

track_samples = copy(tracks)
track_samples[, track_id := NULL]
track_samples[, mode := NULL]
track_samples[, duration := log(duration + 1e-10)]
track_samples[, release_year := log(release_year + 1e-10)]
track_samples[, acousticness := log(acousticness + 1e-10)]
track_samples[, dyn_range_mean := log(dyn_range_mean + 1e-10)]
track_samples[, flatness := log(flatness + 1e-10)]
track_samples[, instrumentalness := log(instrumentalness + 1e-10)]
track_samples[, liveness := log(liveness + 1e-10)]
track_samples[, speechiness := log(speechiness + 1e-10)]
node_names = colnames(track_samples)
correl_mat = cor(track_samples)

graph = pc(suffStat = list(C = correl_mat, n = nrow(track_samples)),
		   indepTest = gaussCItest, alpha=1e-10, labels = node_names)

adjm = wgtMatrix(getGraph(graph), transpose = FALSE)
gD = igraph:::graph.adjacency(adjm)

{% endhighlight %}

</details> <br>

<center> <iframe src="/images/spotify/grpvz.html" height="500px" width="50%" frameBorder="0"></iframe> </center>

There are ton of interesting insights here, I won't go into them, but as an example, `acousticness` is a parent to `dyn_range_mean`, `energy`, `organism`, `acoustic_vector_1`, `acoustic_vector_3` and `acoustic_vector_7`, but depends on nothing. It's quite weird that `duration` is a parent of `release_year` though!

There are a bunch of nonlinearities in the relationships between these variables and not everything is gaussian (most variables aren't) so this graph is approximate, but is interesting nonetheless.

Now, we move onto the `sessions` data.

<details>
<summary> Sessions exploration code </summary>
 
{%highlight R%}

unique_sessions <- sessions[, unique(session_id)]
popular_songs <- sessions[, .N, by = track_id][order(-N)]
popular_songs <- popular_songs[1:10000, track_id]

# acoustic_songs <- tracks[track_id %in% popular_songs][order(-acousticness), track_id]

#################################################
# Transitions between songs

# had memory issues here, garbage collection - gc() was used often
trans_mat <- copy(sessions[track_id %in% popular_songs,
				.(session_id, session_position, track_id)])
setorder(trans_mat, 'session_id', 'session_position')
trans_mat[, pos_next := shift(session_position, type = 'lead'), by = session_id]
trans_mat[, track_next := shift(track_id, type = 'lead'), by = session_id]
trans_mat <- trans_mat[pos_next - session_position == 1,
	.(track_id = factor(track_id, levels = popular_songs, ordered = T),
	  track_next = factor(track_next, levels = popular_songs, ordered = T)
)]
trans_mat <- as.matrix(trans_mat[, table(track_id, track_next)])
dimnames(trans_mat) <- NULL

num_songs <- 50
image(x = 1:num_songs, y = 1:num_songs, log(trans_mat[1:num_songs, 1:num_songs] + 1),
	xlab = 'Popularity Rank of Current Song', ylab = 'Popularity Rank of Next Song',
	main = 'Log Transitions between Top 400 Songs')

#################################################
# Seasonality

library(lubridate)

plot_frame <- function(variable) {
	var <- substitute(variable)
	return(sessions[, .(p = mean(not_skipped + skip_1)),
		by = eval(var)][order(var)])
}

plots <- list()

plots[[1]] <- ggplot(plot_frame(wday(date, T))) +
	geom_point(aes(x = var, y = p)) +
	labs(x = 'Weekday', y = 'Prob of Skip')

plots[[2]] <- ggplot(plot_frame(mday(date))) +
	geom_line(aes(x = var, y = p), linetype = 2) +
	labs(x = 'Day of Month', y = 'Prob of Skip')

plots[[3]] <- ggplot(plot_frame(hour_of_day)) +
	geom_line(aes(x = var, y = p), linetype = 2) +
	labs(x = 'Hour of Day', y = 'Prob of Skip')

plots[[4]] <- ggplot(plot_frame(session_position)) +
	geom_line(aes(x = var, y = p), linetype = 2) +
	labs(x = 'Session Position', y = 'Prob of Skip')

gridExtra::grid.arrange(grobs = plots, nrow = 2)

{% endhighlight %}

</details> <br>

We see that there are cut offs at round popularity figures, so perhaps a lot of transitions are happening due to Top 50 or similar lists. More popular songs seem to transition between themselves. There are also some interesting checkerboard-type patterns, where perhaps some songs feed between themselves a lot, maybe due to being similar in some way. There's also the obvious mass along the diagonal - lots of songs play repeatedly. Making the same plot by acousticness doesn't reveal anything very interesting.

<center> <img src="/images/spotify/trnmt.png" width="50%"> </center>

Predictably, there's seasonality in the skip series, and the acousticness of tracks played, and other variables.

<center> <img src="/images/spotify/seask.png" width="50%"> </center>

<center> <img src="/images/spotify/seaac.png" width="50%"> </center>

## More soon
