---
layout: posts
title:  "Gaussian Process Speech Synthesis (Draft)"
date:   2019-12-31 00:02:15 +0000
categories: stats python
entries_layout: grid
---

Very untidy first working draft of the idea mentioned on the efficient computation page. Here, I fit a spectral mixture to some audio data. I'll implement efficient sampling later, and I'll replace the arbitrary way this is trained with an LSTM-RNN to go straight from text/mel-spectrograms to waveforms.
The idea though, is that we fit a gaussian process to some waveforms in the frequency domain rather than the time domain. This also showcases the power of SymPy. This is, to some extent, original work - I drew from Richard Turner's thesis for the amplitude demodulation part, Andrew Gordon Wilson's papers for the spectral kernel and the LJSpeech dataset for the speech data. This was a learning excercise - it's not meant to be groundbreaking.

Synthesized audio sample:

 <audio controls>
   <source src="/audio/life_synth.wav" type="audio/wav">
   Browser cannot play audio.
 </audio> <br>

<details>
<summary> Python Code </summary>
 
{%highlight python%}


# conda activate stanenv; ipython

import pystan
import sympy as sy
import numpy as np
import pandas as pd
import pickle as pkl
import tensorflow as tf
import simpleaudio as sa
from tqdm import tqdm, trange
import matplotlib.pyplot as plt
from scipy.linalg import toeplitz
from scipy.io import wavfile as wav
from scipy.signal import stft, find_peaks
from scipy.interpolate import UnivariateSpline

sy.init_printing()
md = sy.functions.Abs
sess = tf.InteractiveSession()
plt.style.use("ggplot"); plt.ion()

def spectrum(x, u = 1, return_freq = True):
	n = len(x)
	intm = np.fft.fft(x)
	intm = (intm * intm.conjugate()).real/n
	intm = intm * u/n 
	psd = intm[1:int(np.ceil(0.5 * (n + 1)))]
	if return_freq:
		freq = range(1, len(psd) + 1) 
		freq = np.array(freq, dtype = float)
		freq *= 0.5*n / (u * len(psd))
		return freq, psd
	else:
		return psd

class SimulationData:
	def __init__(self):
		self.num_data = None
		self.time = None
		self.upper_lim = None
		self.kernel_func = None
		self.cholesky_fac = None
	def gen_grid(self, num_data = 500, upper_lim = 5):
		self.num_data = num_data
		self.upper_lim = upper_lim
		self.time = np.linspace(0, upper_lim, num_data)
	def gen_chol(self, kernel_func = None):
		if kernel_func is None:
			kernel_func = self.kernel_func
		C = toeplitz(kernel_func(self.time))
		C += np.identity(len(self.time))*1e-10
		C = self.condition_at_zero(C)
		C += np.identity(len(self.time) - 2)*1e-10
		C = np.linalg.cholesky(C)
		self.cholesky_fac = C
	def simulate(self):
		C = self.cholesky_fac
		z = np.random.normal(size = self.num_data - 2)
		return np.hstack([0.0, (C @ z).reshape(-1), 0.0])
	def gen_expcos_kern(self, l = None, p = None, s = None, noise = 0.0, lambdify = True):
		sm = dict(r = sy.symbols("r", real = True),
			w = sy.symbols("w", real = True, positive = True),
			l = sy.symbols("l", real = True, positive = True),
			p = sy.symbols("p", real = True, positive = True),
			s = sy.symbols("s", real = True, positive = True))
		if l is not None: sm['l'] = l
		if p is not None: sm['p'] = p
		if s is not None: sm['s'] = s
		if None in [l, p, s]: raise NotImplementedError
		self.symbols = sm
		K = sm['s']**2 * sy.exp(-(sm['r']/sm['l'])**2) * sy.cos(2*sm['p']*sy.pi*sm['r'])
		S = sy.fourier_transform(K, sm['r'], sm['w'])
		W = noise**2 / sy.sqrt(2)
		if lambdify:
			S = sy.lambdify(sm['w'], S + W)
			K = sy.lambdify(sm['r'], K)
			def W(x):
				k = np.zeros(len(x))
				k[x == 0] += noise**2
				return k
		self.kernel_func = lambda x: K(x) + W(x)
		self.spectrum = S
		self.white = W
	@staticmethod
	def condition_at_zero(mat):
		n = mat.shape[0]
		indices = np.hstack([range(1, n - 1), 0, n - 1])
		mat = mat[indices, :]
		mat = mat[:, indices]

		K11 = mat[:(n - 2), :(n - 2)]
		K12 = mat[:(n - 2), (n - 2):]
		K22 = mat[(n - 2):, (n - 2):]
		return K11 - (K12 @ np.linalg.inv(K22) @ K12.T)

def spectrum_check(l = 0.5, s = 2.0, p = 0.5, n = 10000):
	r, w = sy.symbols("r, w", real = True)
	K = s**2 * sy.exp(-(r/l)**2) * sy.cos(2*p*sy.pi*r)
	S = sy.fourier_transform(K, r, w)
	S = sy.lambdify(w, S)
	K = sy.lambdify(r, K)

	data = SimulationData()
	data.gen_grid()
	data.gen_chol(K)

	freq, psd = spectrum(data.simulate(), data.upper_lim)
	for i in range(n - 1):
		psd += spectrum(data.simulate(), data.upper_lim)[1]

	s_t = S(data.time)
	plt.plot(data.time, s_t, label = "Theoretical")
	plt.xlim(-0.5, data.upper_lim)
	plt.plot(freq, psd/n, label = "Empirical")
	plt.xlabel("Frequency")
	plt.ylabel("Power")
	plt.legend()

def convergence_check():
	l, s, p, u = 0.5, 2.0, 0.5, 5.0
	r, w = sy.symbols("r, w", real = True)
	s_p, p_p, l_p = sy.symbols("s, p, l", real = True, positive = True)

	K = s**2 * sy.exp(-(r/l)**2) * sy.cos(2*p*sy.pi*r)
	K_t = s_p**2 * sy.exp(-(r/l_p)**2) * sy.cos(2*p_p*sy.pi*r)
	S = sy.fourier_transform(K_t, r, w)
	S = sy.lambdify([w, l_p, p_p, s_p], S, "tensorflow")
	K = sy.lambdify(r, K)
	W = s_p**2 / sy.sqrt(2) # sy.fourier_transform((s_p**2)*sy.exp(-(r/1e-20)**2)/sy.sqrt(2*sy.pi*(1e-20)**2), r, w)
	W = sy.lambdify(s_p, W)

	data = SimulationData()
	data.gen_grid(upper_lim = u)
	data.gen_chol(K)

	l_p_0 = tf.Variable(1.1)
	p_p_0 = tf.Variable(2.2)
	s_p_0 = tf.Variable(0.9)

	l_param = tf.clip_by_value(l_p_0, 1e-5, 1e5)
	p_param = tf.clip_by_value(p_p_0, 1e-5, 1e5)
	s_param = tf.clip_by_value(s_p_0, 1e-5, 1e5)

	freq_obs, spec_obs = spectrum(data.simulate(), u)
	freq_obs = np.array(freq_obs, dtype = "float32")
	spec_obs = np.array(spec_obs, dtype = "float32")

	spec_const = tf.constant(spec_obs)

	add_term = S(freq_obs, l_param, p_param, s_param) + 1e-10
	loss = tf.reduce_sum((spec_const - add_term)**2) # likelihood is too unstable
	step = tf.train.AdamOptimizer().minimize(loss = loss, var_list = [l_p_0, p_p_0, s_p_0])

	sess.run(tf.initialize_all_variables())

	for i in tqdm(range(2000)):
		if i % 50 == 0:
			freq_obs, spec_obs = spectrum(data.simulate(), u)
			freq_obs = np.array(freq_obs, dtype = "float32")
			spec_obs = np.array(spec_obs, dtype = "float32")
			print(sess.run(loss))
		sess.run(step, feed_dict = {spec_const: spec_obs})
	print(np.round(sess.run([l_param, p_param, s_param]), 2))
	print(np.round([l, p, s], 2))

if False: # expt to determine listening ranges for my ear
	t = np.linspace(0, 0.1, 2205)
	f = 2500; l = 0.01; s = 0.01
	C = np.linalg.cholesky(toeplitz(s**2 * np.exp(-(t/l)**2) * np.cos(2*f*np.pi*t)) + np.identity(2205)*1e-10)
	z = C @ np.random.normal(size = 2205)
	f, s = spectrum(z, 0.1)
	audio = np.array(np.tile(z * 100, 10), dtype = "int16")
	audio = sa.play_buffer(audio, 1, 2, 22050)

if __name__ == "__main__":

	# life_sr, life = wav.read("/Users/adityaravuri/Downloads/life.wav")
	# life_sr, life = wav.read("/home/aditya/data/LJSpeech-1.1/wavs/LJ001-0001.wav")
	life_sr, life = wav.read("/Users/adityaravuri/data/LJSpeech-1.1/wavs/LJ001-0001.wav")
	life = np.array(life) if len(life.shape) == 1 else np.array(life[:, 0], dtype = "float64")
	life_scale = life.std()
	life = life/life_scale
	n_t = len(life)
	t = n_t/life_sr

	# model_code = """
	# data {
	# 	int n;     // len
	# 	real x[n]; // audio
	# }
	# parameters {
	# 	real<lower = 0, upper = 1> l;
	# 	real<lower = 0, upper = 10> s;
	# 	vector<lower = -10, upper = 2>[n] sigma;
	# }
	# model {
	# 	sigma[1] ~ normal(0, s);
	# 	sigma[2:n] ~ normal(l * sigma[1:(n - 1)], s*(1 - l^2)^0.5);
	# 	x ~ normal(0, exp(sigma));
	# }
	# """

	# n_s = n_t//40; seg = life[range(n_s)]
	# data_list = dict(n = n_s, x = seg)

	# model = pystan.StanModel(model_code = model_code)
	# with open('ar_amp_model.pkl', 'wb') as f:
	# 	pkl.dump(model, f, protocol = pkl.HIGHEST_PROTOCOL)

	# with open('ar_amp_model.pkl', 'rb') as f:
	# 	model = pkl.load(f)

	# fit = model.sampling(data = data_list, iter = 1000, chains = 1)
	# while fit['value'] < -2950: # 2011.08:
	# 	temp = model.optimizing(data = data_list, as_vector = False)
	# 	if temp['value'] > fit['value']:
	# 		fit = temp

	# plt.plot(np.exp(fit['par']['sigma']) *  2)
	# plt.plot(np.exp(fit['par']['sigma']) * -2)
	# plt.plot(seg)

	# b_a = int(n_t/4); b_b = int(n_t/2); b_c = int(n_t*0.825)
	# plt.vlines(b_a, -3, 3)
	# plt.vlines(b_b, -3, 3)
	# plt.vlines(b_c, -3, 3)

	# envelope = np.log(1 + np.exp(fit['par']['sigma_vec']))
	envelope = np.array(pd.Series(life).rolling(2500).std(center = True).fillna(0.004))
	envelope_div = envelope.copy()
	envelope_div[envelope_div <= 0.2] = 0.2

	stn = life/envelope_div

	segments = tuple([stn[(2217*i):(2217*(i + 1))] for i in range(96)])

	r, w = sy.symbols("r, w", real = True)
	s, p, l = sy.symbols("s, p, l", real = True, positive = True)

	K = s**2 * sy.exp(-(r/l)**2) * sy.cos(2*p*sy.pi*r)
	S = sy.fourier_transform(K, r, w)
	S = sy.lambdify([w, l, p, s], S, "tensorflow")
	K = sy.lambdify([r, l, p, s], K)
	W = s**2 / sy.sqrt(2.0)
	W = sy.lambdify(s, W, "tensorflow")

	v = lambda x: tf.exp(tf.Variable(x))
	generators = []

	bark_scale = [20, 100, 200, 300, 400, 510, 630, 770, 920, 1080,
				  1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700, 4400,
				  5300, 6400, 7700, 9500, 12000, 15500, np.infty]
	bark_scale = pd.DataFrame(dict(cuts_end = bark_scale))
	bark_scale['cuts_start'] = bark_scale.cuts_end.shift(1, fill_value = 0.0)
	bark_scale.reset_index(inplace = True)

	identifier = lambda x: bark_scale[bark_scale.cuts_end >= x].iloc[0, 0]

	for seg in segments:

		freq_obs, spec_obs = spectrum(seg, t * len(seg)/n_t)
		freq_obs = np.array(freq_obs, dtype = "float32")
		spec_obs = np.array(spec_obs, dtype = "float32") + 1e-30

		obs_spectrum = pd.DataFrame(dict(f = freq_obs, s = spec_obs))
		obs_spectrum['index'] = obs_spectrum.f.map(identifier)

		obs_spectrum['s_prime'] = obs_spectrum.groupby('index')['s'].transform('max')
		spec_obs_max = np.array(obs_spectrum.s_prime, dtype = "float32")

		sigma = 1/(1 + v(3.))

		n_sel = len(bark_scale.index)
		ps_to_add = np.array(obs_spectrum.loc[obs_spectrum.s == obs_spectrum.s_prime, 'f'], dtype = "float32")
		ps_non_trainable = len(ps_to_add)
		l_ps = [1/(1 + v(np.random.uniform(1, 3))) for i in range(len(ps_to_add))]
		p_ps = [i for i in ps_to_add]
		s_ps = [1/(1 + v(np.random.uniform(-0.2, 0.2))) for i in range(len(ps_to_add))]

		def spec_gen(x):
			add_term = W(sigma) + 1e-30
			for i in range(len(p_ps)):
				add_term += S(x, l_ps[i], p_ps[i], s_ps[i])
			return add_term

		add_term = spec_gen(freq_obs)

		loss = tf.reduce_sum((tf.log(spec_obs) - tf.log(add_term))**2) # likelihood is too unstable
		loss += tf.reduce_sum((tf.log(spec_obs_max) - tf.log(add_term))**2)
		step = tf.train.AdamOptimizer(0.005).minimize(loss = loss)

		sess.run(tf.initialize_all_variables())

		looper = trange(10000, desc = 'ML')
		for i in looper:
			sess.run(step)
			if i % 50 == 0: looper.set_description('Loss: %g' % sess.run(loss))

		l_ps = sess.run(l_ps); p_ps = p_ps[:ps_non_trainable] + sess.run(p_ps[ps_non_trainable:])
		s_ps = sess.run(s_ps); sigma = np.array(sess.run(sigma), dtype = 'float32')

		def kern(r):
			res = np.zeros(len(r))
			res[r == 0] = sigma**2
			for i in range(len(p_ps)):
				res += K(r, l_ps[i], p_ps[i], s_ps[i])
			return res

		test_data = SimulationData()
		test_data.gen_grid(len(seg), t * len(seg)/n_t)
		test_data.gen_chol(kern)
		generators.append(test_data)
		# plt.plot(test_data.simulate())

		# x = np.linspace(freq_obs.min(), freq_obs.max(), 10000, dtype = "float32")
		# plt.plot(freq_obs, np.log(spec_obs))
		# plt.plot(x, np.log(sess.run(spec_gen(x))))

	# to work on conditioning between segments and efficient sampling
	audio = [generators[i].simulate() for i in range(len(generators))]
	audio = [i/np.std(i) for i in audio]
	audio = np.hstack(audio)
	audio_to_write = np.array(life_scale * audio * envelope[:len(audio)], dtype = "int16")
	wav.write("life_synth.wav", life_sr, np.repeat(audio_to_write, 2).reshape(-1, 2))

{% endhighlight %}
 
</details>
